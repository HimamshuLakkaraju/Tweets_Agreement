{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence,pad_packed_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = pd.read_csv('../data/augmented_training_file/final_train_file2.csv')\n",
    "final_test_file = pd.read_csv('../data/final_test_file.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows grouped by label are:\n",
      "0 class rows: 175598 (40.240)% of total train data\n",
      "2 class rows: 112302 (25.735)% of total train data\n",
      "1 class rows: 148476 (34.025)% of total train data\n"
     ]
    }
   ],
   "source": [
    "data_per_class=Counter(train_file['label'])\n",
    "print(\"Number of rows grouped by label are:\")\n",
    "for i,label in enumerate(data_per_class):\n",
    "    print(f\"{label} class rows: {data_per_class[label]} ({data_per_class[label] / train_file.shape[0]*100:.3f})% of total train data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights to be used for CrossEntropyLoss (increases loss to classes with less data to balance the learning)\n",
      " tensor([0.8284, 0.9797, 1.2952])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\CVAS4\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2], y=0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "436371    1\n",
      "436372    1\n",
      "436373    1\n",
      "436374    1\n",
      "436375    1\n",
      "Name: label, Length: 436376, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight  # .compute_class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(train_file['label']), train_file['label'])\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "print(f\"Class weights to be used for CrossEntropyLoss (increases loss to classes with less data to balance the learning)\\n {class_weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split_size=0.3 # percentage of test split\n",
    "train_split,test_split=train_test_split(train_file, test_size=test_split_size,stratify=train_file['label'],random_state=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if cuda supported GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating customised Image dataset to be used for dataloader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_frame):\n",
    "        self.data = data_frame['encoded_titles_combined']\n",
    "        self.label = data_frame['label']\n",
    "        self.length=len(data_frame)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_data = self.data[idx]\n",
    "        text_data = np.array(text_data[1:-1].split(), dtype=int)\n",
    "        text_data = torch.tensor(text_data)\n",
    "        # print(type(self.label[idx]), label_encoding[self.label[idx]])\n",
    "        label = torch.tensor(self.label[idx]).long()\n",
    "        data=(text_data,label)\n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_dataset=CustomDataset(train_split.reset_index())\n",
    "test_split_dataset=CustomDataset(test_split.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 100\n",
    "loaders = {\n",
    "    'train': DataLoader(train_split_dataset, batch_size=batch, shuffle=True, num_workers=0),\n",
    "    'test': DataLoader(test_split_dataset, batch_size=batch, shuffle=True, num_workers=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an LSTM net\n",
    "class LSTM_simple(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_dimension,lstm_units,hidden_dimension):\n",
    "        super().__init__()\n",
    "        self.embeddings=nn.Embedding(vocab_size,embed_dimension)\n",
    "        self.lstm_layer1= nn.LSTM(embed_dimension,lstm_units,hidden_dimension,bidirectional=True,batch_first=True)\n",
    "        self.full_layer1 = nn.Linear(2*hidden_dimension,3)\n",
    "\n",
    "    def forward(self, text):\n",
    "        text=text.to(device=device)\n",
    "        embedded_text=self.embeddings(text)\n",
    "        lstm_out, (ht, ct) = self.lstm_layer1(embedded_text)\n",
    "        ht=torch.cat((ht[-2, :, :], ht[-1, :, :]), dim=1)\n",
    "        ht=self.full_layer1(ht)\n",
    "        return ht\n",
    "\n",
    "\n",
    "LSTM_simple_model = LSTM_simple(49491, 256, 128, 128).to(device=device) # 49491 is vocab len\n",
    "optimizer=optim.SGD(LSTM_simple_model.parameters(),lr=0.01,momentum=0.9)\n",
    "class_weights=class_weights.to(device=device)\n",
    "loss_func=nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.3333\n"
     ]
    }
   ],
   "source": [
    "# return the accuracy of the test_split\n",
    "def validation(model):\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for sentences, labels in loaders['test']:\n",
    "            sentences.to(device=device)\n",
    "            labels=labels.to(device=device)\n",
    "            test_output = model(sentences)\n",
    "            loss = loss_func(test_output, labels)\n",
    "            pred_y = torch.argmax(test_output, 1).data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "        return accuracy,loss\n",
    "# validation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "training_loss_list = []\n",
    "train_accuracy_list = []\n",
    "validation_loss_list = []\n",
    "validation_accuracy_list = []\n",
    "def train(num_epochs, LSTM_simple_model, loaders):\n",
    "    LSTM_simple_model.train()\n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for i, (data, labels) in enumerate(loaders['train']):\n",
    "            training_loss = []\n",
    "            train_accuracy = []\n",
    "            validation_loss = []\n",
    "            validation_accuracy = []\n",
    "            data.to(device=device)\n",
    "            labels.to(device=device)\n",
    "            step_acc = 0.0\n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(data)   # batch x\n",
    "            b_y = Variable(labels)   # batch y\n",
    "            b_x = b_x.to(device=device)\n",
    "            b_y = b_y.to(device=device)\n",
    "\n",
    "            # clear gradients for this training step\n",
    "            optimizer.zero_grad()\n",
    "            output = LSTM_simple_model(b_x)  # predicted output from the net\n",
    "            pred_y = torch.argmax(output, 1).data.squeeze()\n",
    "\n",
    "            step_acc = (pred_y == b_y).sum().item() / float(labels.size(0))\n",
    "            #calc cross entropy loss\n",
    "            loss = loss_func(output, b_y)\n",
    "            train_accuracy.append(step_acc)\n",
    "            training_loss.append(loss.item())\n",
    "            val_acc, val_loss = validation(LSTM_simple_model)\n",
    "            validation_accuracy.append(val_acc)\n",
    "            validation_loss.append(val_loss)\n",
    "            # backpropagation, compute gradients\n",
    "            loss.backward()     # apply gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            if(i//50==0):\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, acc: {:.4f}' .format(\n",
    "                    epoch + 1, num_epochs, i + 1, total_step, loss.item(), step_acc))\n",
    "\n",
    "train(num_epochs, LSTM_simple_model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_simple_model.state_dict(),'./lstm model.pt')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0c1eaf41ec52b322af8555e1405dc2c6c1d8f2144cde1211d67794db22edf07"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CVAS4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
