{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as aug_word\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "from transformers import pipeline\n",
    "from transformers import pipeline\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_word = aug_word.SynonymAug(aug_min=2, aug_max=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = pd.read_csv('../data//train.csv')\n",
    "final_test_file = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows grouped by label are:\n",
      "unrelated class rows: 175598 (68.475)% of total train data\n",
      "agreed class rows: 74238 (28.949)% of total train data\n",
      "disagreed class rows: 6606 (2.576)% of total train data\n"
     ]
    }
   ],
   "source": [
    "data_per_class = Counter(train_file['label'])\n",
    "print(\"Number of rows grouped by label are:\")\n",
    "for i, label in enumerate(data_per_class):\n",
    "    print(\n",
    "        f\"{label} class rows: {data_per_class[label]} ({data_per_class[label] / train_file.shape[0]*100:.3f})% of total train data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding = {\"unrelated\":0,\"agreed\":1,\"disagreed\":2}\n",
    "# preprocessing to remove special chars and convert text to lowercase.\n",
    "def preprocessing(txt):\n",
    "    txt = re.sub('[^a-zA-Z0-9 ]', '', txt)\n",
    "    txt = txt.lower()\n",
    "    return txt\n",
    "\n",
    "# convert text labels to numbers\n",
    "def convert_labels(txt):\n",
    "    return label_encoding[txt]\n",
    "\n",
    "\n",
    "train_file['title1_en'] = train_file['title1_en'].apply(preprocessing)\n",
    "train_file['title2_en'] = train_file['title2_en'].apply(preprocessing)\n",
    "train_file['label'] = train_file['label'].apply(convert_labels)\n",
    "\n",
    "final_test_file['title1_en'] = final_test_file['title1_en'].apply(preprocessing)\n",
    "final_test_file['title2_en']= final_test_file['title2_en'].apply(preprocessing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows grouped by label are:\n",
      "0 class rows: 175598 (68.475)% of total train data\n",
      "1 class rows: 74238 (28.949)% of total train data\n",
      "2 class rows: 6606 (2.576)% of total train data\n"
     ]
    }
   ],
   "source": [
    "data_per_class = Counter(train_file['label'])\n",
    "print(\"Number of rows grouped by label are:\")\n",
    "for i, label in enumerate(data_per_class):\n",
    "    print(\n",
    "        f\"{label} class rows: {data_per_class[label]} ({data_per_class[label] / train_file.shape[0]*100:.3f})% of total train data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data for agreed and disagreed labels\n",
    "disagreed_df = train_file.loc[train_file['label'] ==2]\n",
    "agreed_df=train_file.loc[train_file['label'] ==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# translator_en_fr = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "# translator_fr_de = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-de\")\n",
    "# translator_de_es = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-de-es\")\n",
    "# translator_es_en = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
    "\n",
    "# def translate(ls):\n",
    "#     en_fr = translator_en_fr(ls)\n",
    "#     trans_en_fr = []\n",
    "#     [trans_en_fr.append(x['translation_text']) for x in en_fr]\n",
    "\n",
    "#     fr_de = translator_fr_de(trans_en_fr)\n",
    "#     trans_fr_de = []\n",
    "#     [trans_fr_de.append(x['translation_text']) for x in fr_de]\n",
    "\n",
    "#     de_es = translator_de_es(trans_fr_de)\n",
    "#     trans_de_es = []\n",
    "#     [trans_de_es.append(x['translation_text']) for x in de_es]\n",
    "\n",
    "#     es_en = translator_es_en(trans_de_es)\n",
    "#     trans_es_en = []\n",
    "#     [trans_es_en.append(x['translation_text'].lower()) for x in es_en]\n",
    "\n",
    "#     return trans_es_en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translated_disagreed_title1=disagreed_df['title1_en'].apply(translate)\n",
    "# translated_disagreed_title2=disagreed_df['title2_en'].apply(translate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmented_text(txt):\n",
    "    generated_text=similar_word.augment(txt)\n",
    "    return generated_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    disagreed_data_title1_en=(disagreed_df['title1_en'].apply(augmented_text))\n",
    "    disagreed_data_title2_en=(disagreed_df['title2_en'].apply(augmented_text))\n",
    "    disagreed_data_label=pd.Series([2]*len(disagreed_data_title1_en))\n",
    "    disagreed_data_title1_en.reset_index(drop=True,inplace=True)\n",
    "    disagreed_data_title2_en.reset_index(drop=True, inplace=True)\n",
    "    augmented_disagreed_data_df = pd.DataFrame({\"title1_en\": disagreed_data_title1_en, \"title2_en\": disagreed_data_title2_en,\n",
    "                                            \"label\": disagreed_data_label})\n",
    "    \n",
    "    augmented_disagreed_data_df['title1_en'] = augmented_disagreed_data_df['title1_en'].apply(preprocessing)\n",
    "    augmented_disagreed_data_df['title2_en'] = augmented_disagreed_data_df['title2_en'].apply(preprocessing)\n",
    "    disagreed_df=pd.concat([disagreed_df, augmented_disagreed_data_df], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Augmentation for agreed class\n",
    "# for i in range(1):\n",
    "#     agreed_data_title1_en = (agreed_df['title1_en'].apply(augmented_text))\n",
    "#     agreed_data_title2_en = (agreed_df['title2_en'].apply(augmented_text))\n",
    "#     agreed_data_label = pd.Series([1]*len(agreed_data_title1_en))\n",
    "#     agreed_data_title1_en.reset_index(drop=True, inplace=True)\n",
    "#     agreed_data_title2_en.reset_index(drop=True, inplace=True)\n",
    "#     augmented_agreed_data_df = pd.DataFrame(\n",
    "#         {\"title1_en\": agreed_data_title1_en, \"title2_en\": agreed_data_title2_en, \"label\": agreed_data_label})\n",
    "\n",
    "#     augmented_agreed_data_df['title1_en'] = augmented_agreed_data_df['title1_en'].apply(\n",
    "#         preprocessing)\n",
    "#     augmented_agreed_data_df['title2_en'] = augmented_agreed_data_df['title2_en'].apply(\n",
    "#         preprocessing)\n",
    "#     agreed_df = pd.concat(\n",
    "#         [agreed_df, augmented_agreed_data_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrelated_df=train_file.loc[train_file['label'] ==0]\n",
    "agreed_df=train_file.loc[train_file['label'] ==1]\n",
    "disagreed_df_orig=train_file.loc[train_file['label'] ==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreed_df=pd.concat([disagreed_df_orig,disagreed_df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_df = pd.concat([unrelated_df, disagreed_df, agreed_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows grouped by label after data augmentation is:\n",
      "0 class rows: 175598 (56.775)% of total train data\n",
      "2 class rows: 59454 (19.223)% of total train data\n",
      "1 class rows: 74238 (24.003)% of total train data\n"
     ]
    }
   ],
   "source": [
    "data_per_class = Counter(final_train_df['label'])\n",
    "print(\"Number of rows grouped by label after data augmentation is:\")\n",
    "for i, label in enumerate(data_per_class):\n",
    "    print(\n",
    "        f\"{label} class rows: {data_per_class[label]} ({data_per_class[label] / final_train_df.shape[0]*100:.3f})% of total train data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists('../data/augmented_training_file/')):\n",
    "    final_train_df.to_csv('../data/augmented_training_file/final_train_file.csv',index=False,columns=['title1_en','title2_en','label'])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0c1eaf41ec52b322af8555e1405dc2c6c1d8f2144cde1211d67794db22edf07"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CVAS4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
