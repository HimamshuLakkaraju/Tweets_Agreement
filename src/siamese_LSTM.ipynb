{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if cuda supported GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = pd.read_csv(\n",
    "    '../data/augmented_training_file/final_train_file2.csv')\n",
    "final_test_file = pd.read_csv('../data/final_test_file.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows grouped by label are:\n",
      "0 class rows: 175598 (40.240)% of total train data\n",
      "2 class rows: 112302 (25.735)% of total train data\n",
      "1 class rows: 148476 (34.025)% of total train data\n"
     ]
    }
   ],
   "source": [
    "data_per_class = Counter(train_file['label'])\n",
    "print(\"Number of rows grouped by label are:\")\n",
    "for i, label in enumerate(data_per_class):\n",
    "    print(\n",
    "        f\"{label} class rows: {data_per_class[label]} ({data_per_class[label] / train_file.shape[0]*100:.3f})% of total train data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights to be used for CrossEntropyLoss (increases loss to classes with less data to balance the learning)\n",
      " tensor([0.8284, 0.9797, 1.2952])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\CVAS4\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2], y=0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "436371    1\n",
      "436372    1\n",
      "436373    1\n",
      "436374    1\n",
      "436375    1\n",
      "Name: label, Length: 436376, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight  # .compute_class_weight\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced', np.unique(train_file['label']), train_file['label'])\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "print(\n",
    "    f\"Class weights to be used for CrossEntropyLoss (increases loss to classes with less data to balance the learning)\\n {class_weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split_size = 0.3  # percentage of test split\n",
    "train_split, test_split = train_test_split(\n",
    "    train_file, test_size=test_split_size, stratify=train_file['label'], random_state=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating customised Image dataset to be used for dataloader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_frame):\n",
    "        # print(data_frame['encoded_titles_combined'])\n",
    "        self.data = data_frame\n",
    "        self.label = data_frame['label']\n",
    "        self.length=len(data_frame)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # label_encoding = {\"unrelated\": 0, \"agreed\": 1, \"disagreed\": 2}\n",
    "        # print(type(self.data[idx]), self.data[idx])\n",
    "        # print(self.data['title1_en_encoded'][idx])\n",
    "        # print(self.data['title2_en_encoded'][idx])\n",
    "        title_1 = self.data['title1_en_encoded'][idx]\n",
    "        title_1= np.array(title_1[1:-1].split(), dtype=int)\n",
    "        title_1=torch.tensor(title_1)\n",
    "\n",
    "        title_2 = self.data['title2_en_encoded'][idx]\n",
    "        title_2= np.array(title_2[1:-1].split(), dtype=int)\n",
    "        title_2=torch.tensor(title_2)\n",
    "\n",
    "        label = torch.tensor(self.label[idx]).long()\n",
    "        data=(title_1,title_2,label)\n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_dataset=CustomDataset(train_split.reset_index())\n",
    "test_split_dataset=CustomDataset(test_split.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 10\n",
    "loaders = {\n",
    "    'train': DataLoader(train_split_dataset, batch_size=batch, shuffle=True, num_workers=0),\n",
    "    'test': DataLoader(test_split_dataset, batch_size=batch, shuffle=True, num_workers=0),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM_simple(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_dimension,lstm_units,hidden_dimension):\n",
    "        super().__init__()\n",
    "        self.lstm_block=nn.Sequential(\n",
    "            nn.Embedding(vocab_size,embed_dimension),\n",
    "            nn.LSTM(embed_dimension,lstm_units,hidden_dimension,bidirectional=True,batch_first=True),\n",
    "            \n",
    "        )\n",
    "        self.out_layer = nn.Linear(2*hidden_dimension, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, title1,title2):\n",
    "        title1=title1.to(device=device)\n",
    "        title2=title2.to(device=device)\n",
    "\n",
    "        title1_lstm_out,(ht_1,ct_1)= self.lstm_block(title1)\n",
    "        title2_lstm_out, (ht_2, ct_2) = self.lstm_block(title2)\n",
    "\n",
    "\n",
    "        out = torch.cat((ht_1[-1, :, :], ht_2[-1, :, :]), dim=1)\n",
    "        # print(ht_1.size(), ht_2.size(), out.size())\n",
    "        out=self.out_layer(out)\n",
    "        # lstm_out, (ht, ct) = self.lstm_layer1(embedded_text)\n",
    "        # ht=torch.cat((ht[-2, :, :], ht[-1, :, :]), dim=1)\n",
    "        # print(ht.size())\n",
    "        # ht=self.full_layer1(ht)\n",
    "        # print(ht.size())\n",
    "        # ht=self.RELU(ht)\n",
    "        # ht = self.full_layer2(ht)\n",
    "        # ht = self.RELU2(ht)\n",
    "        # ht=self.out_layer(ht)\n",
    "        return out\n",
    "\n",
    "        # return self.full_layer1(ht[-1]).to(device=device)\n",
    "\n",
    "\n",
    "LSTM_simple_model = LSTM_simple(49491, 256, 128, 128).to(device=device) # 49491 is vocab len\n",
    "optimizer=optim.SGD(LSTM_simple_model.parameters(),lr=0.01,momentum=0.9)\n",
    "class_weights=class_weights.to(device=device)\n",
    "loss_func=nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_simple(\n",
       "  (lstm_block): Sequential(\n",
       "    (0): Embedding(49491, 256)\n",
       "    (1): LSTM(256, 128, num_layers=128, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (out_layer): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_simple_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the accuracy of the test_split\n",
    "def validation(model):\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for a,b, labels in loaders['test']:\n",
    "            labels = labels.to(device=device)\n",
    "            test_output = model(a,b)\n",
    "            loss = loss_func(test_output, labels)\n",
    "            pred_y = torch.argmax(test_output, 1).data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "        return accuracy, loss\n",
    "# validation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "training_loss_list = []\n",
    "train_accuracy_list = []\n",
    "validation_loss_list = []\n",
    "validation_accuracy_list = []\n",
    "def train(num_epochs, LSTM_simple_model, loaders):\n",
    "    LSTM_simple_model.train()\n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        training_loss = []\n",
    "        train_accuracy = []\n",
    "        validation_loss = []\n",
    "        validation_accuracy = []\n",
    "    \n",
    "        for i, (data1,data2, labels) in enumerate(loaders['train']):\n",
    "            step_acc = 0.0\n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(data1)   # batch x1\n",
    "            b_x2=Variable(data2)\n",
    "            b_y = Variable(labels)   # batch y\n",
    "            b_x = b_x.to(device=device)\n",
    "            b_x2=b_x2.to(device=device)\n",
    "            b_y = b_y.to(device=device)\n",
    "\n",
    "            # clear gradients for this training step\n",
    "            optimizer.zero_grad()\n",
    "            # predicted output from the net\n",
    "            output = LSTM_simple_model(b_x, b_x2)\n",
    "            pred_y = torch.argmax(output, 1).data.squeeze()\n",
    "\n",
    "            step_acc = (pred_y == b_y).sum().item() / float(labels.size(0))\n",
    "            #calc cross entropy loss\n",
    "            loss = loss_func(output, b_y)\n",
    "            train_accuracy.append(step_acc)\n",
    "            training_loss.append(loss.item())\n",
    "            if(i%50==0):\n",
    "                val_acc, val_loss = validation(LSTM_simple_model)\n",
    "                validation_accuracy.append(val_acc)\n",
    "                validation_loss.append(val_loss)\n",
    "            # backpropagation, compute gradients\n",
    "            loss.backward()     # apply gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "        \n",
    "            if(i%10==0):\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, acc: {:.4f}' .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(), step_acc))\n",
    "        training_loss_list.append(np.mean(training_loss))\n",
    "        train_accuracy_list.append(np.mean(train_accuracy))\n",
    "        validation_loss_list.append(np.mean(validation_loss))\n",
    "        validation_accuracy_list.append(np.mean(validation_accuracy))\n",
    "\n",
    "\n",
    "train(num_epochs, LSTM_simple_model, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_simple_model.state_dict(),'./saved_models/lstm_model_siamese.pt')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0c1eaf41ec52b322af8555e1405dc2c6c1d8f2144cde1211d67794db22edf07"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CVAS4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
